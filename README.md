# üß† Treinamento de Modelo de Classifica√ß√£o de Sa√∫de Fetal

Este script Python (`train_notebook.py`) implementa um pipeline completo de Machine Learning, focando no **pr√©-processamento de dados**, **treinamento** de um modelo de **Deep Learning** (Rede Neural Densa) e **rastreamento** do experimento usando **MLflow**.

---

## O que o C√≥digo Faz

O c√≥digo executa as seguintes etapas:

1.  **Carregamento de Dados:** Baixa o dataset `fetal_health_reduced.csv` do GitHub (reposit√≥rio `lectures-cdas-2023`).
2.  **Pr√©-processamento:**
    * **Normaliza** (StandardScaler) as features do dataset.
    * **Divide** os dados em conjuntos de treino e teste (`test_size=0.3`).
    * **Ajusta** os labels da vari√°vel target (`fetal_health`) subtraindo 1 para adequar-se √† indexa√ß√£o de classes (0, 1, 2).
3.  **Configura√ß√£o do Modelo:** Cria uma **Rede Neural Sequencial Densa** (DNN) para classifica√ß√£o de 3 classes, usando:
    * Duas camadas ocultas (`Dense`) com 10 unidades e ativa√ß√£o **ReLU**.
    * Uma camada de sa√≠da (`Dense`) com 3 unidades e ativa√ß√£o **Softmax**.
    * Compila√ß√£o com `loss='sparse_categorical_crossentropy'` e otimizador **Adam**.
4.  **Rastreamento (MLflow):** Configura as credenciais e o URI de tracking para registrar o experimento no **DagsHub**. O `mlflow.keras.autolog` √© ativado para rastrear automaticamente par√¢metros e m√©tricas durante o treinamento.
5.  **Treinamento:** Treina o modelo usando o m√©todo `.fit()` por **50 epochs**, registrando todas as informa√ß√µes no MLflow.

---

## üíª Modelo de Deep Learning

| Tipo | Arquitetura | Objetivo |
| :--- | :--- | :--- |
| **Modelo** | Rede Neural Densa (DNN) Sequencial | Classifica√ß√£o |
| **Dados** | Indicadores de Sa√∫de Fetal | Prever 3 classes de sa√∫de fetal. |
| **Camadas** | `InputLayer`, `Dense(10, relu)`, `Dense(10, relu)`, `Dense(3, softmax)` | |
| **Otimizador** | Adam | |
| **Loss** | `sparse_categorical_crossentropy` | Adequado para classifica√ß√£o multi-classe inteira. |

---

## üöÄ Como Rodar o C√≥digo

Para garantir que todas as depend√™ncias estejam isoladas, utilize um **Ambiente Virtual (`venv`)**.

### 1. Pr√©-requisitos

Voc√™ precisar√° ter o Python (vers√£o compat√≠vel com TensorFlow/Keras, idealmente Python 3.9+) instalado.

### 2. Configurar o Ambiente Virtual

Crie e ative o ambiente virtual:

```bash
# Crie o ambiente virtual
python3 -m venv venv

# Ative o ambiente virtual
# No Linux/macOS:
source venv/bin/activate
# No Windows (Command Prompt):
# venv\Scripts\activate.bat
# No Windows (PowerShell):
# venv\Scripts\Activate.ps1
```

### 3. Instalar Depend√™ncias
Este script requer TensorFlow/Keras, MLflow, Pandas e Scikit-learn.

Crie um arquivo requirements.txt com o seguinte conte√∫do:

```bash
tensorflow
keras
mlflow
pandas
matplotlib
scikit-learn
```

Em seguida, instale:

```bash
pip install -r requirements.txt
```

### 4. Executar o Script
Com o ambiente ativado e as depend√™ncias instaladas, execute o arquivo:


```bash
python train_notebook.py
```

O script ser√° executado, o modelo ser√° treinado por 50 epochs e o experimento ser√° registrado no MLflow.



### 3. Ap√≥s configurar o ambiente virtual e as vari√°veis de .env execute o fastApi
```bash
uvicorn app.main:app --host 0.0.0.0 --reload
```

### 4. Teste de carga na api - digite o comando abaixo no diretorio do projeto (n√£o esque√ßa de instalar o pacote locust no python)
```bash
locust
```

No navegador abra a p√°gina do Locust e configure um teste:
Por exemplo, ser√° simulado 1000 usu√°rios, a cada segundo ir√° acessar 10 usu√°rios de uma vez, no host da api.
<img width="711" height="399" alt="image" src="https://github.com/user-attachments/assets/12ac5928-fae2-44bf-8b05-113d4a9c981e" />

Ap√≥s executar o teste voc√™ pode visualizar um gr√°fico com o n√∫mero de requests, percentual de tempo de resposta por requisi√ß√£o e n√∫mero de usu√°rios usando a api.
<img width="1196" height="715" alt="image" src="https://github.com/user-attachments/assets/4066133f-96a1-4139-8e06-4e56fb5f3421" />

As configura√ß√µes de request ficam no arquivo locustfile.py do projeto.





